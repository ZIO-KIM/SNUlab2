{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# image data\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GPU setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus =tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    # tensorflow가 첫번째 gpu만 사용하도록 제한\n",
    "    try: \n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.test.is_gpu_available()\n",
    "#tf.test.is_built_with_cuda()\n",
    "tf.test.is_built_with_gpu_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization - only mass\n",
    "lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/02_01_0001_*')\n",
    "\n",
    "test = Image.open(lst[0])\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(1, len(lst)): \n",
    "    tmp = Image.open(lst[i])\n",
    "    test = np.concatenate((test, tmp), axis = 1)\n",
    "\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization - only mass\n",
    "lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/02_01_0002_*')\n",
    "\n",
    "test = Image.open(lst[0])\n",
    "plt.figure(figsize = (10, 10))\n",
    "for i in range(1, len(lst)): \n",
    "    tmp = Image.open(lst[i])\n",
    "    test = np.concatenate((test, tmp), axis = 1)\n",
    "    \n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization - only mass\n",
    "lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/02_01_0003_*')\n",
    "\n",
    "test = Image.open(lst[0])\n",
    "plt.figure(figsize = (20, 20))\n",
    "for i in range(1, len(lst)): \n",
    "    tmp = Image.open(lst[i])\n",
    "    test = np.concatenate((test, tmp), axis = 1)\n",
    "\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualization - only mass - ppl 1 from 9\n",
    "\n",
    "for idx in range(1, 10): \n",
    "    lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/02_01_000{}_*'.format(idx))\n",
    "\n",
    "    test = Image.open(lst[0])\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    for i in range(1, len(lst)): \n",
    "        tmp = Image.open(lst[i])\n",
    "        test = np.concatenate((test, tmp), axis = 1)\n",
    "        \n",
    "    print(\"patient index: \", idx)\n",
    "    plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualization - only mass - ppl 10 from 30\n",
    "\n",
    "for idx in range(10, 31): \n",
    "    lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/02_01_00{}_*'.format(idx))\n",
    "\n",
    "    test = Image.open(lst[0])\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    for i in range(1, len(lst)): \n",
    "        tmp = Image.open(lst[i])\n",
    "        test = np.concatenate((test, tmp), axis = 1)\n",
    "        \n",
    "    print(\"patient index: \", idx)\n",
    "    plt.imshow(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count min max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pd.DataFrame(os.listdir('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/'))\n",
    "patient['id'] = patient[0].str[0:10]\n",
    "patient.groupby(['id']).count().sort_values([0], ascending = False)\n",
    "# min 1\n",
    "# max 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pd.DataFrame(os.listdir('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/PRE/'))\n",
    "patient['id'] = patient[0].str[0:10]\n",
    "patient.groupby(['id']).count().sort_values([0], ascending = False)\n",
    "# min 1\n",
    "# max 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pd.DataFrame(os.listdir('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Test_data/ART/'))\n",
    "patient['id'] = patient[0].str[0:10]\n",
    "patient.groupby(['id']).count().sort_values([0], ascending = False)\n",
    "# min 2\n",
    "# max 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pd.DataFrame(os.listdir('/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Test_data/PRE/'))\n",
    "patient['id'] = patient[0].str[0:10]\n",
    "patient.groupby(['id']).count().sort_values([0], ascending = False)\n",
    "# min 2\n",
    "# max 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCM header check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcm header check\n",
    "import pydicom\n",
    "\n",
    "path__ = '/home/ncp/workspace/202002n035/035.신장암 진단을 위한 의료 영상 데이터/01.데이터/신장암2/1.Training/원천데이터/02_01_0001/02_01_0001_ART/0001.dcm'\n",
    "header_01 = pydicom.dcmread(path__, stop_before_pixels = True)\n",
    "header_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['name', 'modality'])\n",
    "data = [{'name' : '0', 'modality': str(header_01[0x0008, 0x0001030][0:])}]\n",
    "tmp = pd.DataFrame(data)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcm header별 modality list\n",
    "path = '/home/ncp/workspace/202002n035/035.신장암 진단을 위한 의료 영상 데이터/01.데이터/신장암2/1.Training/원천데이터/'\n",
    "patient = os.listdir(path)\n",
    "df = pd.DataFrame(columns = ['name', 'modality'])\n",
    "lst = []\n",
    "\n",
    "for ppl in patient: \n",
    "    deep_path = path + ppl + '/' + '{}_ART'.format(ppl) + '/'\n",
    "    filelist = os.listdir(deep_path)\n",
    "    for file in filelist: \n",
    "        try: \n",
    "            header = pydicom.dcmread(deep_path + file, stop_before_pixels = True)\n",
    "            data = [{'name' : ppl, 'modality': str(header[0x0008, 0x0001030][0:])}]\n",
    "            tmp = pd.DataFrame(data)\n",
    "            df = pd.concat([df, tmp], axis = 0)\n",
    "        except Exception: \n",
    "            lst.append(ppl)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby(['modality']).count().reset_index()\n",
    "df_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modality_kidney_list = df.loc[df['modality'].isin(['CT Kidney (3P) + 3D', 'CT Kidney (3P) + 3D (contrast)']) == True, 'name'].unique()\n",
    "len(modality_kidney_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modality_kidney_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_pelvis_list = df.loc[df['modality'].isin(['Pelvis^00_Kidney_3D (Adult)']) == True, 'name'].unique()\n",
    "len(modality_pelvis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 사람별 ct 이미지 장수 확인\n",
    "\n",
    "n_list = []\n",
    "\n",
    "for ppl in modality_kidney_list: \n",
    "    lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing/TRAIN/ART/{}_*'.format(ppl))\n",
    "    lst.sort()\n",
    "    n_list.append(len(lst))\n",
    "    print(ppl, \"N: \", len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 사람별 ct 이미지 장수 확인\n",
    "\n",
    "n_list = []\n",
    "\n",
    "for ppl in modality_pelvis_list: \n",
    "    lst = glob('/home/ncp/workspace/blocks1/kidneyData_windowing/TRAIN/ART/{}_*'.format(ppl))\n",
    "    lst.sort()\n",
    "    n_list.append(len(lst))\n",
    "    print(ppl, \"N: \", len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = pd.DataFrame(n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0장인 사람이?\n",
    "# 0drop후 describe\n",
    "\n",
    "n_list = n_list.loc[n_list[0] != 0].reset_index(drop = True)\n",
    "n_list[0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 쓸 때 실행\n",
    "# abnormal : RCC (악성)\n",
    "# normal : aml + onco (양성)\n",
    "\n",
    "ART_train_path = '/home/ncp/workspace/blocks3/zio_code/kidneyData_windowing/TRAIN/ART/'\n",
    "ART_test_path = '/home/ncp/workspace/blocks3/zio_code/kidneyData_windowing/TEST/ART/'\n",
    "PRE_train_path = '/home/ncp/workspace/blocks3/zio_code/kidneyData_windowing/TRAIN/PRE/'\n",
    "PRE_test_path = '/home/ncp/workspace/blocks3/zio_code/kidneyData_windowing/TEST/PRE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass 만 쓸 때 실행 - mass 데이터를 악성 양성으로 분류해서 다시 저장해야 함\n",
    "# abnormal : RCC (악성)\n",
    "# normal : aml + onco (양성)\n",
    "\n",
    "ART_train_path = '/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/ART/'\n",
    "ART_test_path = '/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Test_data/ART/'\n",
    "PRE_train_path = '/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Train_data/PRE/'\n",
    "PRE_test_path = '/home/ncp/workspace/blocks1/kidneyData_windowing_mass/Test_data/PRE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scan(path): \n",
    "    # read scan\n",
    "    volume = Image.open(path).convert('L')\n",
    "    volume = np.array(volume)\n",
    "\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터용\n",
    "\n",
    "def padding_stacking(data_path, cancer_type): \n",
    "    ## create distinct list of patients ##\n",
    "    file_list = os.listdir(data_path + cancer_type + '/')\n",
    "    patient = []\n",
    "    for items in file_list: \n",
    "        patient.append(items[0:10])\n",
    "\n",
    "    patient = list(set(patient))\n",
    "    print(\"total distinct patient N: \", len(patient))\n",
    "\n",
    "    ## create empty datasets ##\n",
    "    scans_final = np.zeros((512, 512, 128))\n",
    "    ppl_scan_list = []\n",
    "\n",
    "    ## iterate through distinct patient list and process ##\n",
    "    for ppl in patient: \n",
    "\n",
    "        ## 사람별로 path list 생성, path list에서 ct 불러와서 stack ## \n",
    "        ## (512, 512, n) 장의 file 생성됨 ##\n",
    "        ppl_path = []\n",
    "        ppl_scan = np.zeros((512, 512))\n",
    "        for x in os.listdir(data_path + cancer_type + '/'): \n",
    "            if x[0:10] == ppl: \n",
    "                ppl_path.append(x)\n",
    "        for path in ppl_path: \n",
    "            ppl_scan = np.dstack((ppl_scan, process_scan(data_path + cancer_type + '/' + path)))  # one layer of zero padding added on top\n",
    "\n",
    "        print(\"patient id: \", ppl)\n",
    "        print(\"ppl_scan shape: \", ppl_scan.shape)\n",
    "\n",
    "        ## zero pad to (512, 512, 128) ##\n",
    "        height, width, depth = ppl_scan.shape\n",
    "        pad_len = (128-depth)//2 # 양쪽에 padding 할 length 정의\n",
    "\n",
    "        if depth >= 128: # if depth >= 128 then truncate\n",
    "            if depth % 2 == 0: \n",
    "                pad_len = (depth-128)//2\n",
    "                ppl_scan_padded = ppl_scan[:, :, pad_len:depth-pad_len]\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "            else: \n",
    "                pad_len = (depth-128)//2\n",
    "                ppl_scan_padded = ppl_scan[:, :, pad_len:depth-pad_len-1]\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "        else: # if depth < 128 than pad\n",
    "            if depth % 2 == 0: \n",
    "                ppl_scan_padded = np.pad(ppl_scan, ((0,0), (0,0), (pad_len, pad_len)), 'constant')\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "            else: \n",
    "                ppl_scan_padded = np.pad(ppl_scan, ((0,0), (0,0), (pad_len, pad_len+1)), 'constant')\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "\n",
    "        ppl_scan_list.append(ppl_scan_padded) # padding 완료된 file을 ppl_scan_list 에 저장\n",
    "        print(\"---------------------\") \n",
    "\n",
    "    # 사람별 생성 및 process 된 ppl_scan을 순회하면서 (N, 512, 512, 128) 로 저장 ##\n",
    "    scans_final = np.array([ppl_scan_list[i] for i in range(len(ppl_scan_list))])\n",
    "    print(\"scans_final shape: \", scans_final.shape) \n",
    "    \n",
    "    return scans_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass 데이터용 - 수정 필요\n",
    "\n",
    "def padding_stacking(data_path, cancer_type): \n",
    "    ## create distinct list of patients ##\n",
    "    file_list = os.listdir(data_path + cancer_type + '/')\n",
    "    patient = []\n",
    "    for items in file_list: \n",
    "        patient.append(items[0:10])\n",
    "\n",
    "    patient = list(set(patient))\n",
    "    print(\"total distinct patient N: \", len(patient))\n",
    "\n",
    "    ## create empty datasets ##\n",
    "    scans_final = np.zeros((512, 512, 128))\n",
    "    ppl_scan_list = []\n",
    "\n",
    "    ## iterate through distinct patient list and process ##\n",
    "    for ppl in patient: \n",
    "\n",
    "        ## 사람별로 path list 생성, path list에서 ct 불러와서 stack ## \n",
    "        ## (512, 512, n) 장의 file 생성됨 ##\n",
    "        ppl_path = []\n",
    "        ppl_scan = np.zeros((512, 512))\n",
    "        for x in os.listdir(data_path + cancer_type + '/'): \n",
    "            if x[0:10] == ppl: \n",
    "                ppl_path.append(x)\n",
    "        for path in ppl_path: \n",
    "            ppl_scan = np.dstack((ppl_scan, process_scan(data_path + cancer_type + '/' + path)))  # one layer of zero padding added on top\n",
    "\n",
    "        print(\"patient id: \", ppl)\n",
    "        print(\"ppl_scan shape: \", ppl_scan.shape)\n",
    "\n",
    "        ## zero pad to (512, 512, 128) ##\n",
    "        height, width, depth = ppl_scan.shape\n",
    "        pad_len = (128-depth)//2 # 양쪽에 padding 할 length 정의\n",
    "\n",
    "        if depth >= 128: # if depth >= 128 then truncate\n",
    "            if depth % 2 == 0: \n",
    "                pad_len = (depth-128)//2\n",
    "                ppl_scan_padded = ppl_scan[:, :, pad_len:depth-pad_len]\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "            else: \n",
    "                pad_len = (depth-128)//2\n",
    "                ppl_scan_padded = ppl_scan[:, :, pad_len:depth-pad_len-1]\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "        else: # if depth < 128 than pad\n",
    "            if depth % 2 == 0: \n",
    "                ppl_scan_padded = np.pad(ppl_scan, ((0,0), (0,0), (pad_len, pad_len)), 'constant')\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "            else: \n",
    "                ppl_scan_padded = np.pad(ppl_scan, ((0,0), (0,0), (pad_len, pad_len+1)), 'constant')\n",
    "                print(\"padded ppl_scan shape: \", ppl_scan_padded.shape)\n",
    "\n",
    "        ppl_scan_list.append(ppl_scan_padded) # padding 완료된 file을 ppl_scan_list 에 저장\n",
    "        print(\"---------------------\") \n",
    "\n",
    "    # 사람별 생성 및 process 된 ppl_scan을 순회하면서 (N, 512, 512, 128) 로 저장 ##\n",
    "    scans_final = np.array([ppl_scan_list[i] for i in range(len(ppl_scan_list))])\n",
    "    print(\"scans_final shape: \", scans_final.shape) \n",
    "    \n",
    "    return scans_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART train : RCC (abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ART_train_abnormal_scans = padding_stacking(ART_train_path, 'RCC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_train_abnormal_scans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART train: AML + onco (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ART_train_normal_scans = padding_stacking(ART_train_path, 'AML + onco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART test: RCC (abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_test_abnormal_scans = padding_stacking(ART_test_path, 'RCC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART test: AML + onco (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ART_test_normal_scans = padding_stacking(ART_test_path, 'AML + onco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE train: RCC (abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE_train_abnormal_scans = padding_stacking(PRE_train_path, 'RCC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE train: AML + onco (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE_train_normal_scans = padding_stacking(PRE_train_path, 'AML + onco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE test: RCC (abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE_test_abnormal_scans = padding_stacking(PRE_test_path, 'RCC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE test: AML + onco (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE_test_normal_scans = padding_stacking(PRE_test_path, 'AML + onco')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART\n",
    "print(\"ART_train_abnormal_scans shape: \", ART_train_abnormal_scans.shape)\n",
    "print(\"ART_train_normal_scans shape: \", ART_train_normal_scans.shape)\n",
    "print(\"ART_test_abnormal_scans shape: \", ART_test_abnormal_scans.shape)\n",
    "print(\"ART_test_normal_scans shape: \", ART_test_normal_scans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "np.savetxt('ART_train_abnormal_scans', ART_train_abnormal_scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PRE\n",
    "# print(\"PRE_train_abnormal_scans shape: \", PRE_train_abnormal_scans.shape)\n",
    "# print(\"PRE_train_normal_scans shape: \", PRE_train_normal_scans.shape)\n",
    "# print(\"PRE_test_abnormal_scans shape: \", PRE_test_abnormal_scans.shape)\n",
    "# print(\"PRE_test_normal_scans shape: \", PRE_test_normal_scans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART 먼저 하고 PRE 해야함 (메모리 에러 남)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(ART_train_normal_labels) * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_train_abnormal_labels = np.array([1 for _ in range(len(ART_train_abnormal_scans))])\n",
    "ART_train_normal_labels = np.array([0 for _ in range(len(ART_train_normal_scans))])\n",
    "\n",
    "# split 7:3 for validation\n",
    "abnormal_train_idx = round(len(ART_train_abnormal_labels) * 0.7)\n",
    "normal_train_idx = round(len(ART_train_normal_labels) * 0.7)\n",
    "\n",
    "x_train = np.concatenate((ART_train_abnormal_scans[:50], ART_train_normal_scans[:50]), axis = 0)\n",
    "y_train = np.concatenate((ART_train_abnormal_labels[50:100], ART_train_normal_labels[50:100]), axis = 0)\n",
    "\n",
    "x_val = np.concatenate((ART_train_abnormal_scans[:50], ART_train_normal_scans[:50]), axis = 0)\n",
    "y_val = np.concatenate((ART_train_abnormal_labels[50:100], ART_train_normal_labels[50:100]), axis = 0)\n",
    "\n",
    "print(\"Number of samples in train and validation are %d and %d\" %(x_train.shape[0], x_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(width = 512, height = 512, depth = 128): \n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "    \n",
    "    x = layers.Conv3D(filters = 64, kernel_size = 3, activation = \"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters = 64, kernel_size = 3, activation = \"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters = 128, kernel_size = 3, activation = \"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters = 128, kernel_size = 3, activation = \"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters = 256, kernel_size = 3, activation = \"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters = 256, kernel_size = 1, activation = \"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units = 512, activation = \"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = layers.Dense(units = 1, activation = \"sigmoid\")(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name = \"3dcnn\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(width = 512, height = 512, depth = 128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps = 100000, decay_rate = 0.96, staircase = True\n",
    ")\n",
    "model.compile(\n",
    "    loss = \"binary_crossentropy\", \n",
    "    optimizer = keras.optimizers.Adam(learning_rate = lr_schedule), \n",
    "    metrics = [\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"ART_abnormal_3d_image_classification.hdf5\", save_best_only = True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor = \"val_acc\", patience = 15)\n",
    "\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "        ART_train_abnormal_scans,\n",
    "        validation_data = ART_test_abnormal_scans, \n",
    "        epochs = epochs, \n",
    "        shuffle = True, \n",
    "        verbose = 2, \n",
    "        callbacks = [checkpoint_cb, early_stopping_cb]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddd",
   "language": "python",
   "name": "ddd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
